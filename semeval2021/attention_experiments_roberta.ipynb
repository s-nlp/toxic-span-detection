{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 17 05:14:03 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   37C    P8    26W / 260W |   7203MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8     9W / 260W |   6215MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   34C    P8     5W / 260W |   9070MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8    11W / 260W |   5698MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8     1W / 260W |   5706MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8    14W / 260W |   5216MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    10W / 260W |   5764MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    15W / 260W |   1340MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4694      C   /opt/.pyenv/versions/3.7.4/bin/python        885MiB |\n",
      "|    0      9727      C   /opt/.pyenv/versions/3.7.4/bin/python       1407MiB |\n",
      "|    0     15151      C   /opt/.pyenv/versions/3.7.4/bin/python       1081MiB |\n",
      "|    0     23791      C   /opt/.pyenv/versions/3.7.4/bin/python       3819MiB |\n",
      "|    1      4694      C   /opt/.pyenv/versions/3.7.4/bin/python       1029MiB |\n",
      "|    1     17743      C   python                                      5173MiB |\n",
      "|    2     24051      C   /opt/.pyenv/versions/3.7.4/bin/python       9059MiB |\n",
      "|    3     17742      C   python                                      5685MiB |\n",
      "|    4     17744      C   python                                      5693MiB |\n",
      "|    5     17745      C   python                                      5203MiB |\n",
      "|    6     17746      C   python                                      5751MiB |\n",
      "|    7      9443      C   /home/logacheva/anaconda3/bin/python        1329MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from box import Box\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "\n",
    "import re\n",
    "MAX_SENTENCE_LEN = 82\n",
    "\n",
    "from utils import preprocess\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import tqdm, trange\n",
    "\n",
    "seed = 678\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(7)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "DATA_PATH = '../../../semeval2021_task/data/'\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + 'tsd_train.csv')\n",
    "trial = pd.read_csv(DATA_PATH + 'tsd_trial.csv')\n",
    "\n",
    "train['spans'] = train.spans.apply(literal_eval)\n",
    "trial['spans'] = trial.spans.apply(literal_eval)\n",
    "texts = list(train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../models/roberta_full/model_out were not used when initializing RobertaForMultiLabelSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "CLASSIFICATION_MODEL_PATH = '../../models/roberta_full/model_out'\n",
    "CLASSIFICATION_LABELS_PATH = '../../labels'\n",
    "\n",
    "from fast_bert.prediction import BertClassificationPredictor\n",
    "\n",
    "predictor = BertClassificationPredictor(CLASSIFICATION_MODEL_PATH, CLASSIFICATION_LABELS_PATH, \n",
    "                                        multi_label=True, model_type='roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../models/roberta_full/model_out were not used when initializing RobertaForMultiLabelSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "lern = predictor.get_learner()\n",
    "pretrained_weights = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_weights)\n",
    "MASK_INDEX = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "lern.model.eval();\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {v: k for k, v in tokenizer.get_vocab().items()}\n",
    "\n",
    "def toks_to_words(token_ids):\n",
    "    \"\"\" Merge subword tokens into whole words \"\"\"\n",
    "    indices = []\n",
    "    for i, token_id in enumerate(token_ids):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        token_text = v[token_id]\n",
    "        if not token_text.startswith('Ġ') and token_text.isalpha() and i != 1:\n",
    "            indices.append(i)\n",
    "        else:\n",
    "            if indices:\n",
    "                toks = [v[token_ids[t]] for t in indices]\n",
    "                word = ''.join(toks)\n",
    "                new_indices = [index - 1 for index in indices]\n",
    "                yield new_indices, word\n",
    "            indices = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "config = RobertaConfig.from_pretrained('roberta-base', output_attentions=True)\n",
    "lern.model.roberta.config = config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink(nums_arr, att_arr):\n",
    "    \"\"\"\n",
    "    When words are splitted by several tokens by BERT, each token has\n",
    "    its own feature vector. this function takes the mean of these vectors\n",
    "    and assign it to the original word.\n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    prev_i = 0\n",
    "    #print(att_arr.shape)\n",
    "    for arr in nums_arr:#for each splitted word\n",
    "        fig = att_arr[:, :, prev_i:arr[0]] #add all previous words\n",
    "        nafig = att_arr[:, :, arr].mean(axis=2)[:, :, np.newaxis] #add mean of token features\n",
    "        #print(fig.shape)\n",
    "        #print(nafig.shape)\n",
    "        res.append(fig)\n",
    "        res.append(nafig)\n",
    "        prev_i = arr[-1] + 1 #make the current word \"previous\"\n",
    "        #print(prev_i, att_arr.shape[-1])\n",
    "    #print(\"before checker\")\n",
    "    #for fig in res:\n",
    "        #print(fig.shape)\n",
    "    if prev_i < att_arr.shape[-1]: #just to be safe and not overstep the array\n",
    "        res.append(att_arr[:, :, prev_i:])\n",
    "    #print(\"after checker\")\n",
    "    #for fig in res:\n",
    "        #print(fig.shape)\n",
    "    result = np.concatenate(res, axis=2).T\n",
    "    #print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_for_words(text: str, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Get attention values for all heads averaged over all layers and \n",
    "    attention values for all layers averaged over all heads.\n",
    "    \"\"\"\n",
    "    toks = tokenizer.encode(text) \n",
    "    nums = [arr for (arr, string) in list(toks_to_words(toks)) if len(arr) > 1]\n",
    "    #print(nums)\n",
    "    sentence = torch.tensor(toks).unsqueeze(0)\n",
    "    sentence = sentence.cuda()\n",
    "    out = model.roberta(sentence, output_attentions=True, return_dict=True)\n",
    "    #we cut the CLS and SEP tokens\n",
    "    attentions = torch.cat(out['attentions'], dim=0).cpu()[:, :, 1:-1, 1:-1]\n",
    "    attentions = attentions.mean(dim=2).detach().numpy()\n",
    "    #print(attentions.shape)\n",
    "    shrunk_attentions = shrink(nums, attentions).reshape(-1, 144)\n",
    "    return shrunk_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getword(arr, text):\n",
    "    \"\"\"\n",
    "    Using a span from a dataset, obtain a word\n",
    "    \"\"\"\n",
    "    ans = ''\n",
    "    for i in range(len(arr)):\n",
    "        elem = arr[i]\n",
    "        if  i != 0 and i != len(arr) - 1 and elem != arr[i-1] + 1:\n",
    "            ans += ' '\n",
    "            ans += text[elem]\n",
    "        else:\n",
    "            ans += text[elem]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(span, text, tokenizer):\n",
    "    target_toks = tokenizer.encode(getword(span, text))\n",
    "    #print(target_toks)\n",
    "    toks = tokenizer.encode(text)\n",
    "    #print(toks)\n",
    "    toks = [string for (arr, string) in list(toks_to_words(toks))]\n",
    "    #print(toks)\n",
    "    target_toks = [string for (arr, string) in list(toks_to_words(target_toks))]\n",
    "    #print(target_toks)\n",
    "    target = []\n",
    "    #check if the word is in spanned words\n",
    "    for tok in toks:\n",
    "        if len(target_toks) > 0 and tok.strip('Ġ') == target_toks[0].strip('Ġ'):\n",
    "            target.append(1)\n",
    "            target_toks = target_toks[1:]\n",
    "        else:\n",
    "            target.append(0)\n",
    "    return toks, target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Another',\n",
       "  'Ġviolent',\n",
       "  'Ġand',\n",
       "  'Ġaggressive',\n",
       "  'Ġimmigrant',\n",
       "  'Ġkilling',\n",
       "  'Ġa',\n",
       "  'Ġinnocent',\n",
       "  'Ġand',\n",
       "  'Ġintelligent',\n",
       "  'ĠUS',\n",
       "  'ĠCitizen',\n",
       "  '....',\n",
       "  'ĠSarcasm'],\n",
       " [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_target(train.spans.iloc[0], train.text.iloc[0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(train.text.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0], 'Another'),\n",
       " ([1], 'Ġviolent'),\n",
       " ([2], 'Ġand'),\n",
       " ([3], 'Ġaggressive'),\n",
       " ([4], 'Ġimmigrant'),\n",
       " ([5], 'Ġkilling'),\n",
       " ([6], 'Ġa'),\n",
       " ([7], 'Ġinnocent'),\n",
       " ([8], 'Ġand'),\n",
       " ([9], 'Ġintelligent'),\n",
       " ([10], 'ĠUS'),\n",
       " ([11], 'ĠCitizen'),\n",
       " ([12], '....'),\n",
       " ([13, 14, 15], 'ĠSarcasm')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(toks_to_words(tokenizer.encode(train.text.iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7939it [07:41, 17.20it/s]\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "data = np.array([])\n",
    "for span, text in tqdm(zip(train['spans'], train['text'])):\n",
    "    word_attentions = get_attention_for_words(text, lern.model, tokenizer)\n",
    "    #print(word_attentions.shape)\n",
    "    if len(data) == 0:\n",
    "        data = word_attentions\n",
    "    else:\n",
    "        data = np.vstack((data, word_attentions))\n",
    "    words, new_target = make_target(span, text, tokenizer)\n",
    "    #print(new_target)\n",
    "    try:\n",
    "        assert len(new_target) == word_attentions.shape[0]\n",
    "    except:\n",
    "        print(new_target)\n",
    "        print(words)\n",
    "        print(word_attentions.shape)\n",
    "        print(len(words))\n",
    "        print(text)\n",
    "        break\n",
    "    target += new_target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markov/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [00:12<00:00, 57.30it/s]\n"
     ]
    }
   ],
   "source": [
    "trial_data = np.array([])\n",
    "for text in tqdm(trial['text']):\n",
    "    word_atts = get_attention_for_words(text, lern.model, tokenizer)\n",
    "    if len(trial_data) == 0:\n",
    "        trial_data = word_atts\n",
    "    else:\n",
    "        trial_data = np.vstack((trial_data, word_atts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = logreg.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6838"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21978"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probas = logreg.predict_proba(data)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334930\n"
     ]
    }
   ],
   "source": [
    "print(len(train_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334930 0\n",
      "25072 1\n",
      "13038 2\n",
      "9742 3\n",
      "8045 4\n",
      "6838 5\n",
      "5915 6\n",
      "5114 7\n",
      "4260 8\n",
      "3230 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_pred = np.where(train_probas > i/10, 1, 0)\n",
    "    print(train_pred.sum(), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_probas = logreg.predict_proba(trial_data)[:, 1]\n",
    "trial_preds = np.where(trial_probas > 0.18, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "690it [00:00, 2136.52it/s]\n"
     ]
    }
   ],
   "source": [
    "trial_target = []\n",
    "for span, text in tqdm(zip(trial['spans'], trial['text'])):\n",
    "    words, new_target = make_target(span, text, tokenizer)\n",
    "    trial_target += new_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trial_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5242082271568983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(f1_score(trial_preds, trial_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
